# Toxicity Comments Rating

This work is an attend on the <a href='https://www.kaggle.com/competitions/jigsaw-toxic-severity-rating/'>Jigsaw Rate Severity of Toxic Comments</a> competition on Kaggle. 

### Goal
The aim of this competition is to rank comments in order of severity of toxicity. Each comment should be scored according to their relative toxicity. Comments with a higher degree of toxicity should receive a higher numerical value compared to comments with a lower degree of toxicity.

### Approaches
All approaches are listed in the Jupyter Notebook and can be taken from it. 
(Clone the repository and open it in Jupyter lab to use the hrefs and navigate easier through the notebook)

### Dataset 
_Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive._

In this competition was no training data given. Instead we had to refer to previous Jigsaw competitions for data that might be useful to train models. 
For additional information see the competition description on Kaggle.
